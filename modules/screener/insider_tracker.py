"""
ì„ì› ë§¤ìˆ˜ ì¶”ì  ëª¨ë“ˆ (Insider Trading Tracker)
SEC Form 4ë¥¼ ë¶„ì„í•˜ì—¬ ì„ì›ë“¤ì˜ ìì‚¬ì£¼ ë§¤ìˆ˜ ì¶”ì 
ë°ì´í„° ì†ŒìŠ¤: SEC EDGAR (ê³µê°œ ë°ì´í„°, í•©ë²•ì )
"""

import requests
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import time
from bs4 import BeautifulSoup


class InsiderTracker:
    """ì„ì› ë§¤ìˆ˜ ì¶”ì  í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.sec_base_url = "https://www.sec.gov"
        self.headers = {
            'User-Agent': 'Investment Research App contact@example.com',
            'Accept-Encoding': 'gzip, deflate',
            'Host': 'www.sec.gov'
        }
        self.request_delay = 0.11  # SEC Rate Limit: ì´ˆë‹¹ 10 ìš”ì²­
    
    def get_insider_trades(self, ticker: str, months: int = 3) -> pd.DataFrame:
        """
        ì„ì› ê±°ë˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        
        Args:
            ticker: ì¢…ëª© ì½”ë“œ (ì˜ˆ: 'AAPL')
            months: ì¡°íšŒ ê¸°ê°„ (ê°œì›”)
        
        Returns:
            DataFrame: ì„ì› ê±°ë˜ ë‚´ì—­
        """
        print(f"\nğŸ“‹ ì„ì› ê±°ë˜ ë°ì´í„° ìˆ˜ì§‘: {ticker} (ìµœê·¼ {months}ê°œì›”)")
        
        try:
            # 1. CIK ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
            cik = self._get_cik(ticker)
            if not cik:
                print(f"âš ï¸ CIK ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ticker}")
                return self._empty_dataframe()
            
            # 2. Form 4 ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            form4_list = self._get_form4_list(cik, months)
            if not form4_list:
                print(f"âš ï¸ Form 4 ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {ticker}")
                return self._empty_dataframe()
            
            # 3. ê° Form 4 íŒŒì‹±
            trades = []
            for i, form_url in enumerate(form4_list[:20]):  # ìµœëŒ€ 20ê°œ
                print(f"  ğŸ“„ {i+1}/{min(len(form4_list), 20)} íŒŒì‹± ì¤‘...")
                trade_data = self._parse_form4(form_url)
                if trade_data:
                    trades.extend(trade_data)
                time.sleep(self.request_delay)
            
            if not trades:
                return self._empty_dataframe()
            
            # 4. DataFrame ìƒì„±
            df = pd.DataFrame(trades)
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date', ascending=False)
            
            print(f"âœ… {len(df)}ê°œ ì„ì› ê±°ë˜ ìˆ˜ì§‘ ì™„ë£Œ!")
            return df
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return self._empty_dataframe()
    
    def _get_cik(self, ticker: str) -> Optional[str]:
        """ì¢…ëª© ì½”ë“œë¡œ CIK ì½”ë“œ ì°¾ê¸°"""
        try:
            url = "https://www.sec.gov/files/company_tickers.json"
            response = requests.get(url, headers=self.headers)
            time.sleep(self.request_delay)
            
            if response.status_code != 200:
                return None
            
            data = response.json()
            
            for item in data.values():
                if item['ticker'].upper() == ticker.upper():
                    cik = str(item['cik_str']).zfill(10)
                    print(f"  âœ… CIK ì½”ë“œ: {cik}")
                    return cik
            
            return None
            
        except Exception as e:
            print(f"  âŒ CIK ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def _get_form4_list(self, cik: str, months: int) -> List[str]:
        """Form 4 íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        try:
            url = f"{self.sec_base_url}/cgi-bin/browse-edgar"
            params = {
                'action': 'getcompany',
                'CIK': cik,
                'type': '4',
                'dateb': '',
                'owner': 'include',
                'count': 100
            }
            
            response = requests.get(url, params=params, headers=self.headers)
            time.sleep(self.request_delay)
            
            if response.status_code != 200:
                return []
            
            soup = BeautifulSoup(response.text, 'html.parser')
            table = soup.find('table', {'class': 'tableFile2'})
            
            if not table:
                return []
            
            form4_urls = []
            cutoff_date = datetime.now() - timedelta(days=months * 30)
            
            rows = table.find_all('tr')[1:]
            for row in rows:
                cols = row.find_all('td')
                if len(cols) < 4:
                    continue
                
                date_str = cols[3].text.strip()
                try:
                    filing_date = datetime.strptime(date_str, '%Y-%m-%d')
                    if filing_date < cutoff_date:
                        continue
                except:
                    continue
                
                doc_link = cols[1].find('a')
                if doc_link:
                    href = doc_link.get('href')
                    full_url = f"{self.sec_base_url}{href}"
                    form4_urls.append(full_url)
            
            print(f"  âœ… {len(form4_urls)}ê°œ Form 4 ë°œê²¬")
            return form4_urls
            
        except Exception as e:
            print(f"  âŒ Form 4 ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _parse_form4(self, url: str) -> List[Dict]:
        """Form 4 íŒŒì¼ íŒŒì‹±"""
        try:
            response = requests.get(url, headers=self.headers)
            if response.status_code != 200:
                return []
            
            soup = BeautifulSoup(response.text, 'html.parser')
            xml_link = None
            for a in soup.find_all('a'):
                href = a.get('href', '')
                if '.xml' in href and 'primary_doc' not in href:
                    xml_link = f"{self.sec_base_url}{href}"
                    break
            
            if not xml_link:
                return []
            
            time.sleep(self.request_delay)
            xml_response = requests.get(xml_link, headers=self.headers)
            
            if xml_response.status_code != 200:
                return []
            
            xml_soup = BeautifulSoup(xml_response.content, 'xml')
            
            owner = xml_soup.find('reportingOwner')
            if not owner:
                return []
            
            insider_name = self._safe_get_text(owner, 'rptOwnerName')
            title = self._safe_get_text(owner, 'officerTitle')
            
            trades = []
            non_derivatives = xml_soup.find_all('nonDerivativeTransaction')
            
            for transaction in non_derivatives:
                date_elem = transaction.find('transactionDate')
                if not date_elem or not date_elem.find('value'):
                    continue
                trade_date = date_elem.find('value').text
                
                code_elem = transaction.find('transactionCode')
                if not code_elem:
                    continue
                trans_code = code_elem.text.strip()
                
                if trans_code != 'P':  # P = ë§¤ìˆ˜ë§Œ
                    continue
                
                shares_elem = transaction.find('transactionShares')
                shares = float(shares_elem.find('value').text) if shares_elem else 0
                
                price_elem = transaction.find('transactionPricePerShare')
                price = float(price_elem.find('value').text) if price_elem else 0
                
                value = shares * price
                
                trades.append({
                    'date': trade_date,
                    'insider_name': insider_name,
                    'title': title if title else 'N/A',
                    'transaction_type': 'ë§¤ìˆ˜',
                    'shares': int(shares),
                    'price_per_share': round(price, 2),
                    'value': round(value, 2)
                })
            
            return trades
            
        except Exception as e:
            return []
    
    def _safe_get_text(self, element, tag: str) -> str:
        """XML ìš”ì†Œì—ì„œ ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        found = element.find(tag)
        if found:
            return found.text.strip()
        return "N/A"
    
    def _empty_dataframe(self) -> pd.DataFrame:
        """ë¹ˆ DataFrame ë°˜í™˜"""
        return pd.DataFrame(columns=[
            'date', 'insider_name', 'title', 'transaction_type',
            'shares', 'price_per_share', 'value'
        ])
    
    def analyze_insider_sentiment(self, df: pd.DataFrame) -> Dict:
        """
        ì„ì› ë§¤ìˆ˜ íŒ¨í„´ ë¶„ì„
        
        Args:
            df: ì„ì› ê±°ë˜ ë°ì´í„°
        
        Returns:
            Dict: ë¶„ì„ ê²°ê³¼
        """
        if df.empty:
            return {
                'signal': 'ë°ì´í„° ì—†ìŒ',
                'score': 0,
                'total_buys': 0,
                'total_value': 0,
                'unique_insiders': 0
            }
        
        recent_df = df[df['date'] >= (datetime.now() - timedelta(days=90))]
        
        if recent_df.empty:
            return {
                'signal': 'ìµœê·¼ ê±°ë˜ ì—†ìŒ',
                'score': 0,
                'total_buys': 0,
                'total_value': 0,
                'unique_insiders': 0
            }
        
        total_buys = len(recent_df)
        total_value = recent_df['value'].sum()
        unique_insiders = recent_df['insider_name'].nunique()
        
        # ì ìˆ˜ ê³„ì‚° (0~100)
        score = 0
        
        # 1. ê±°ë˜ íšŸìˆ˜ (ìµœëŒ€ 40ì )
        if total_buys >= 5:
            score += 40
        elif total_buys >= 3:
            score += 30
        elif total_buys >= 2:
            score += 20
        elif total_buys >= 1:
            score += 10
        
        # 2. ê±°ë˜ ê¸ˆì•¡ (ìµœëŒ€ 40ì )
        if total_value >= 1000000:
            score += 40
        elif total_value >= 500000:
            score += 30
        elif total_value >= 100000:
            score += 20
        elif total_value > 0:
            score += 10
        
        # 3. ì°¸ì—¬ ì„ì› ìˆ˜ (ìµœëŒ€ 20ì )
        if unique_insiders >= 3:
            score += 20
        elif unique_insiders >= 2:
            score += 15
        elif unique_insiders >= 1:
            score += 10
        
        # ì‹ í˜¸ íŒì •
        if score >= 70:
            signal = 'ğŸŸ¢ ê°•í•œ ë§¤ìˆ˜ ì‹ í˜¸'
        elif score >= 50:
            signal = 'ğŸŸ¡ ì¤‘ë¦½ì  ì‹ í˜¸'
        elif score >= 30:
            signal = 'ğŸŸ  ì•½í•œ ì‹ í˜¸'
        else:
            signal = 'âšª ì‹ í˜¸ ì—†ìŒ'
        
        return {
            'signal': signal,
            'score': score,
            'total_buys': total_buys,
            'total_value': total_value,
            'unique_insiders': unique_insiders,
            'avg_value_per_trade': total_value / total_buys if total_buys > 0 else 0
        }


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ“‹ ì„ì› ë§¤ìˆ˜ ì¶”ì  ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    tracker = InsiderTracker()
    
    print("\nğŸ Apple ì„ì› ê±°ë˜ ë¶„ì„...")
    df = tracker.get_insider_trades("AAPL", months=6)
    
    if not df.empty:
        print(f"\nâœ… {len(df)}ê°œ ê±°ë˜ ë°œê²¬!")
        print("\nìµœê·¼ ê±°ë˜:")
        print(df.head(10))
        
        analysis = tracker.analyze_insider_sentiment(df)
        print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
        print(f"  ì‹ í˜¸: {analysis['signal']}")
        print(f"  ì ìˆ˜: {analysis['score']}/100")
        print(f"  ì´ ë§¤ìˆ˜ íšŸìˆ˜: {analysis['total_buys']}íšŒ")
        print(f"  ì´ ë§¤ìˆ˜ ê¸ˆì•¡: ${analysis['total_value']:,.0f}")
        print(f"  ì°¸ì—¬ ì„ì› ìˆ˜: {analysis['unique_insiders']}ëª…")
    else:
        print("âš ï¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
    
    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")